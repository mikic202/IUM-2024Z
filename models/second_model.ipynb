{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from random import sample\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import math\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'embeding_models/embeding_v3_8_dim.pt'\n",
    "model = torch.jit.load(model_path).encoder.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735858800.0\n"
     ]
    }
   ],
   "source": [
    "BASE_DATE = datetime.strptime(\"2025-01-03\", '%Y-%m-%d').timestamp()\n",
    "print(BASE_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_raw_data = pd.read_json(Path('../data_v2/tracks_artists.jsonl'), lines=True)\n",
    "\n",
    "\n",
    "# NORMALIZE DATES\n",
    "tracks_raw_data[\"release_date\"] = (pd.to_datetime(tracks_raw_data[\"release_date\"], format='mixed').apply(lambda x: x.timestamp())).div(BASE_DATE)\n",
    "\n",
    "# NORMALIZE DURATION\n",
    "tracks_raw_data[\"duration_ms\"] = tracks_raw_data[\"duration_ms\"].div(tracks_raw_data[\"duration_ms\"].max())\n",
    "\n",
    "# NORMALIZE TEMPO\n",
    "tracks_raw_data[\"tempo\"] = tracks_raw_data[\"tempo\"].div(tracks_raw_data[\"tempo\"].max())\n",
    "\n",
    "# EXPLICITE ENCODING\n",
    "tracks_raw_data[\"explicit\"] = tracks_raw_data[\"explicit\"].apply(lambda x: [0, 1] if x else [1, 0])\n",
    "\n",
    "# processs ARTIST HASH\n",
    "\n",
    "def postprocess_hash_to_list(x):\n",
    "    str_x = str(x)\n",
    "    if len(str_x) < 8:\n",
    "        str_x = \"0\" * (8 - len(str_x)) + str_x\n",
    "    return [int(x) for x in str_x]\n",
    "\n",
    "tracks_raw_data[\"id_artist_hash\"] = tracks_raw_data[\"id_artist_hash\"].apply(postprocess_hash_to_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracksDataset(Dataset):\n",
    "    def __init__(self, tracks_data: pd.DataFrame):\n",
    "        self.data = tracks_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        return self.data.iloc[idx].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        unpacked_data = []\n",
    "        for data in self.data.iloc[idx].drop(\"id_track\").values:\n",
    "            if type(data) != list:\n",
    "                unpacked_data.append(data)\n",
    "            else:\n",
    "                unpacked_data += data\n",
    "        return torch.Tensor(unpacked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedings_per_id = pd.DataFrame()\n",
    "embedings_per_id[\"id_track\"] = tracks_raw_data[\"id_track\"]\n",
    "embedings_per_id[\"embeding\"] = [model(torch.Tensor(x)).detach().cpu().numpy() for x in TracksDataset(tracks_raw_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_intigers = [687, 852, 528, 562, 426, 1092, 171, 250, 223, 265, 981, 607, 738, 1020, 510, 899, 596, 1047, 826, 669, 923, 905, 1063, 139, 1031]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id               timestamp  user_id                track_id  \\\n",
      "0       89426 2024-09-17 10:51:23.000      260  1xPec5BN0Zxv77zrWKq43S   \n",
      "1       89427 2023-05-20 00:35:36.227      260  7s0lDK7y3XLmI7tcsRAbW0   \n",
      "2       89427 2023-05-20 00:38:48.054      260  48lQegoLqGAzaRLnMwK0mO   \n",
      "3       89427 2023-05-20 00:43:30.802      260  48lQegoLqGAzaRLnMwK0mO   \n",
      "4       89427 2023-05-20 00:44:59.387      260  4usVYcPlxRgRet6YashdCJ   \n",
      "\n",
      "  event_type  \n",
      "0       play  \n",
      "1       play  \n",
      "2       play  \n",
      "3       like  \n",
      "4       play  \n"
     ]
    }
   ],
   "source": [
    "files_to_load = [file for file in os.listdir(\"../data_v2/sessions\") if int(file.split(\".\")[0].split(\"_\")[-1]) not in test_intigers]\n",
    "\n",
    "raw_sessions_data = pd.concat([pd.read_json(Path(f'../data_v2/sessions/{file}'), lines=True) for file in files_to_load])\n",
    "print(raw_sessions_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sesions_data = raw_sessions_data.merge(embedings_per_id, left_on=\"track_id\", right_on=\"id_track\").drop(\"id_track\", axis=1)\n",
    "merged_sesions_data[\"timestamp\"] = (pd.to_datetime(merged_sesions_data[\"timestamp\"], format='mixed').apply(lambda x: x.timestamp())).div(BASE_DATE)\n",
    "merged_sesions_data = pd.get_dummies(merged_sesions_data, columns=[\"event_type\"], dtype = int)\n",
    "\n",
    "merged_sesions_data = [pd.DataFrame(y) for _, y in merged_sesions_data.groupby('session_id', as_index=False) if len(y) > 1]\n",
    "\n",
    "NUMBER_OF_INPUTS = 12\n",
    "EMBEDING_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomUserSesionsDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        return self.data.iloc[idx].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sessions = []\n",
    "        for session in self.data[idx].drop(\"track_id\", axis=1).drop(\"session_id\", axis=1).drop(\"user_id\", axis=1).values:\n",
    "            unpacked_data = np.array([])\n",
    "            for data in session:\n",
    "                unpacked_data = np.append(unpacked_data, data)\n",
    "            sessions.append(torch.tensor(unpacked_data))\n",
    "        return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sesions_dataset = CustomUserSesionsDataset(merged_sesions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARE_PERCENTAGE = 0.25\n",
    "\n",
    "def pad_sessions_collate(batch, pad_value=0.0):\n",
    "    input_sequences = [\n",
    "    ]\n",
    "    output_sequences = [\n",
    "    ]\n",
    "\n",
    "    for batch_element in batch:\n",
    "        number_of_sequence_data = len(batch_element)\n",
    "        number_of_reference_data = math.ceil(number_of_sequence_data * COMPARE_PERCENTAGE)\n",
    "\n",
    "        input_sequences.append(torch.stack(batch_element[:number_of_sequence_data - number_of_reference_data]))\n",
    "        output_sequences.append(sample(batch_element[number_of_sequence_data - number_of_reference_data:], 1)[0])\n",
    "\n",
    "    x_lens = [len(x) for x in input_sequences]\n",
    "\n",
    "    padded_input_sequence = pad_sequence(input_sequences, batch_first=True, padding_value=pad_value)\n",
    "\n",
    "    return padded_input_sequence, torch.stack([x[1:EMBEDING_SIZE + 1] for x in output_sequences]), x_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(user_sesions_dataset, batch_size=8192, shuffle=True, collate_fn=pad_sessions_collate, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class UsertPreferenceGenerator(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(UsertPreferenceGenerator, self).__init__()\n",
    "#         self.num_layers = 1\n",
    "#         self.hidden_size = 256\n",
    "#         self.rnn = torch.nn.LSTM(input_size=NUMBER_OF_INPUTS, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "#         self.act2 = torch.nn.LeakyReLU()\n",
    "#         self.act1 = torch.nn.Hardsigmoid()\n",
    "#         self.fc1 = torch.nn.Linear(self.hidden_size, 128)\n",
    "#         self.fc2 = torch.nn.Linear(128, EMBEDING_SIZE)\n",
    "\n",
    "#     def init_hidden(self, batch_size):\n",
    "#         hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "#         state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "#         return hidden, state\n",
    "\n",
    "#     def forward(self, x, x_lens, hidden):\n",
    "\n",
    "#         x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "#         packed_output, hidden = self.rnn(x_packed, hidden)\n",
    "#         output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "#         x = self.fc1(self.act1(output))\n",
    "#         x = self.fc2(self.act2(x))\n",
    "\n",
    "#         return x, hidden\n",
    "\n",
    "\n",
    "class UsertPreferenceGenerator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UsertPreferenceGenerator, self).__init__()\n",
    "        self.num_layers = 3\n",
    "        self.hidden_size = 32\n",
    "        self.rnn = torch.nn.LSTM(input_size=NUMBER_OF_INPUTS, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.act2 = torch.nn.ReLU()\n",
    "        self.act1 = torch.nn.Hardsigmoid()\n",
    "        self.fc1 = torch.nn.Linear(self.hidden_size, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, EMBEDING_SIZE)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "\n",
    "    def forward(self, x, x_lens, hidden):\n",
    "\n",
    "        x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden = self.rnn(x_packed, hidden)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        x = self.fc1(self.act1(output))\n",
    "        x = self.fc2(self.act2(x))\n",
    "\n",
    "        return x, hidden\n",
    "\n",
    "\n",
    "class UsertPreferenceGenerator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UsertPreferenceGenerator, self).__init__()\n",
    "        self.num_layers = 3\n",
    "        self.hidden_size = NUMBER_OF_INPUTS\n",
    "        self.rnn = torch.nn.LSTM(input_size=NUMBER_OF_INPUTS, hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "        self.fc1 = torch.nn.Linear(self.hidden_size, EMBEDING_SIZE)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "\n",
    "        x_packed = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden = self.rnn(x_packed)\n",
    "        output, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        x = self.fc1(output)\n",
    "        # x = self.fc2(self.act2(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UsertPreferenceGenerator(\n",
      "  (rnn): LSTM(12, 512, batch_first=True)\n",
      "  (act2): LeakyReLU(negative_slope=0.01)\n",
      "  (fc2): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = UsertPreferenceGenerator().to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "loss_fun = nn.L1Loss()\n",
    "\n",
    "# torch.onnx.export(model,[] ,'loop.onnx', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UsertPreferenceGenerator(\n",
      "  (rnn): LSTM(12, 12, num_layers=3, batch_first=True)\n",
      "  (fc1): Linear(in_features=12, out_features=8, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 47.2\n",
      "Epoch: 1, loss: 46.4\n",
      "Epoch: 2, loss: 45.6\n",
      "Epoch: 3, loss: 44.8\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model = UsertPreferenceGenerator().to(device)\n",
    "print(model)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
    "loss_fun = nn.L1Loss()\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(4):\n",
    "    loss_sum = 0\n",
    "    for x, targets, x_lens in train_loader:\n",
    "        x = x.float().to(device)\n",
    "        targets = targets.to(torch.float).to(device)\n",
    "\n",
    "        # hidden, state = model.init_hidden(x.size(0))\n",
    "        # hidden, state = hidden.to(device), state.to(device)\n",
    "\n",
    "        preds = model(x, x_lens)\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        last_pred = preds[:, -1, :]\n",
    "        loss = loss_fun(last_pred, targets)\n",
    "        loss.backward()\n",
    "        loss_sum += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {loss_sum:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'recomendation_models/user_preference_model_v3_8_dim.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             aten::_pad_packed_sequence        10.52%       1.156ms        32.01%       3.519ms       3.519ms     909.000us         8.04%       3.522ms       3.522ms             1  \n",
      "                                             aten::sort        12.44%       1.368ms        27.00%       2.968ms       1.484ms       1.377ms        12.18%       2.978ms       1.489ms             2  \n",
      "                            aten::_pack_padded_sequence         6.33%     696.000us        24.89%       2.736ms       2.736ms     561.000us         4.96%       2.739ms       2.739ms             1  \n",
      "                                            aten::slice        11.40%       1.253ms        14.70%       1.616ms      11.145us       1.564ms        13.84%       2.080ms      14.345us           145  \n",
      "                                       aten::contiguous         1.33%     146.000us        11.77%       1.294ms      46.214us     193.000us         1.71%       1.370ms      48.929us            28  \n",
      "                                             aten::lstm         0.66%      73.000us        12.34%       1.356ms       1.356ms      75.000us         0.66%       1.359ms       1.359ms             1  \n",
      "                                            aten::copy_         5.47%     601.000us        11.93%       1.311ms      21.492us       1.299ms        11.49%       1.299ms      21.295us            61  \n",
      "                                       aten::_cudnn_rnn        10.02%       1.101ms        11.42%       1.255ms       1.255ms       1.210ms        10.71%       1.262ms       1.262ms             1  \n",
      "                                            aten::clone         3.03%     333.000us         9.93%       1.092ms      39.000us     341.000us         3.02%       1.177ms      42.036us            28  \n",
      "                                     aten::index_select         2.27%     249.000us         3.69%     406.000us      67.667us     814.000us         7.20%     929.000us     154.833us             6  \n",
      "                                           aten::arange         3.99%     439.000us         8.31%     914.000us     228.500us     453.000us         4.01%     927.000us     231.750us             4  \n",
      "                                       aten::as_strided         0.65%      71.000us         0.65%      71.000us       0.464us     549.000us         4.86%     549.000us       3.588us           153  \n",
      "                                           aten::linear         0.27%      30.000us         1.49%     164.000us     164.000us      21.000us         0.19%     478.000us     478.000us             1  \n",
      "                                       aten::empty_like         1.46%     160.000us         3.24%     356.000us      12.276us     215.000us         1.90%     437.000us      15.069us            29  \n",
      "                                            aten::addmm         0.66%      73.000us         0.80%      88.000us      88.000us     416.000us         3.68%     416.000us     416.000us             1  \n",
      "                                            aten::empty         2.38%     262.000us         2.38%     262.000us       5.574us     391.000us         3.46%     391.000us       8.319us            47  \n",
      "                                             aten::view         1.02%     112.000us         1.02%     112.000us       1.836us     327.000us         2.89%     327.000us       5.361us            61  \n",
      "                                             aten::full         0.31%      34.000us         1.08%     119.000us     119.000us      29.000us         0.26%     183.000us     183.000us             1  \n",
      "                                               aten::to         0.20%      22.000us         4.27%     469.000us     117.250us      28.000us         0.25%     163.000us      40.750us             4  \n",
      "                                         aten::_to_copy         0.34%      37.000us         4.03%     443.000us     221.500us      31.000us         0.27%     135.000us      67.500us             2  \n",
      "                                            aten::fill_         0.43%      47.000us         0.57%      63.000us      63.000us     133.000us         1.18%     133.000us     133.000us             1  \n",
      "                                            aten::index         0.64%      70.000us         0.75%      82.000us      82.000us      73.000us         0.65%      87.000us      87.000us             1  \n",
      "                                          aten::resize_         0.46%      51.000us         0.46%      51.000us       6.375us      81.000us         0.72%      81.000us      10.125us             8  \n",
      "                                         aten::scatter_         0.33%      36.000us         0.44%      48.000us      48.000us      45.000us         0.40%      53.000us      53.000us             1  \n",
      "                                              aten::cat         0.25%      27.000us         0.30%      33.000us      33.000us      52.000us         0.46%      52.000us      52.000us             1  \n",
      "                                        aten::transpose         0.20%      22.000us         0.29%      32.000us      10.667us      28.000us         0.25%      40.000us      13.333us             3  \n",
      "                                          aten::reshape         0.10%      11.000us         0.18%      20.000us      10.000us      16.000us         0.14%      27.000us      13.500us             2  \n",
      "                                                aten::t         0.09%      10.000us         0.19%      21.000us      21.000us      12.000us         0.11%      24.000us      24.000us             1  \n",
      "                                    aten::empty_strided         0.21%      23.000us         0.21%      23.000us      11.500us      21.000us         0.19%      21.000us      10.500us             2  \n",
      "                                           aten::select         0.12%      13.000us         0.15%      16.000us      16.000us      15.000us         0.13%      19.000us      19.000us             1  \n",
      "                                             aten::set_         0.08%       9.000us         0.12%      13.000us       6.500us      14.000us         0.12%      19.000us       9.500us             2  \n",
      "                                       aten::lift_fresh         0.01%       1.000us         0.01%       1.000us       1.000us       5.000us         0.04%       5.000us       5.000us             1  \n",
      "                              aten::cudnn_is_acceptable         0.01%       1.000us         0.01%       1.000us       1.000us       3.000us         0.03%       3.000us       3.000us             1  \n",
      "                                        cudaEventRecord        12.13%       1.334ms        12.13%       1.334ms       1.091us       0.000us         0.00%       0.000us       0.000us          1223  \n",
      "                                        cudaMemcpyAsync         5.19%     570.000us         5.19%     570.000us      19.655us       0.000us         0.00%       0.000us       0.000us            29  \n",
      "                                  cudaStreamSynchronize         0.13%      14.000us         0.13%      14.000us       7.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                       cudaLaunchKernel         3.03%     333.000us         3.03%     333.000us       3.202us       0.000us         0.00%       0.000us       0.000us           104  \n",
      "                                  cudaStreamIsCapturing         0.02%       2.000us         0.02%       2.000us       1.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                  cudaStreamGetPriority         0.00%       0.000us         0.00%       0.000us       0.000us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                       cudaDeviceGetStreamPriorityRange         0.01%       1.000us         0.01%       1.000us       0.500us       0.000us         0.00%       0.000us       0.000us             2  \n",
      "                                    cudaStreamWaitEvent         0.03%       3.000us         0.03%       3.000us       0.120us       0.000us         0.00%       0.000us       0.000us            25  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.05%       5.000us         0.05%       5.000us       0.333us       0.000us         0.00%       0.000us       0.000us            15  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.04%       4.000us         0.04%       4.000us       4.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                  cudaDeviceSynchronize         1.73%     190.000us         1.73%     190.000us     190.000us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 10.993ms\n",
      "Self CUDA time total: 11.301ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-12-24 14:20:35 4443:4443 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-12-24 14:20:35 4443:4443 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-12-24 14:20:35 4443:4443 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "with profiler.profile(use_cuda=True) as prof:\n",
    "    preds, _ = model(x, x_lens, (hidden, state))\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.993923\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4.7692013\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m0.50016433\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m1.8391552\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m4.93348\u001b[39;49m\u001b[43m   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m1.0898505\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m1.9289817\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.784728\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3.9150748\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m5.587146\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m7.239292\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;241;43m7.1324625\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m2.55823\u001b[39;49m\u001b[43m   \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m4.176082\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m8.504707\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m5.0005746\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2.202329\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mUsertPreferenceGenerator.forward\u001b[0;34m(self, x, x_lens, hidden)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_lens, hidden):\n\u001b[0;32m---> 16\u001b[0m     x_packed \u001b[38;5;241m=\u001b[39m \u001b[43mpack_padded_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_lens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m     packed_output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x_packed, hidden)\n\u001b[1;32m     18\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m pad_packed_sequence(packed_output, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pt/lib/python3.11/site-packages/torch/nn/utils/rnn.py:259\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     lengths, sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(lengths, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 259\u001b[0m     sorted_indices \u001b[38;5;241m=\u001b[39m sorted_indices\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m)\n\u001b[1;32m    260\u001b[0m     batch_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_first \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mindex_select(batch_dim, sorted_indices)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model([[0.993923, 4.7692013 ,  0.50016433,  1.8391552 , -4.93348   ,  1.0898505 ,\n",
    "          1.9289817 , 10.784728  , -3.9150748 ,  5.587146  ,  7.239292  ,\n",
    "          7.1324625 ,  2.55823   ,  4.176082  ,  8.504707  ,  5.0005746 ,\n",
    "         -2.202329, 0, 1, 0]], [1], torch.zeros(1, 1, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185842         124   0.993923      101  1ZAkJE2vi1wbo7tyvgWuXN   \n",
      "1185843         124   0.993923      101  6YpSiNQN8pVzJMOX2fXGHm   \n",
      "1185844         124   0.993924      101  6YpSiNQN8pVzJMOX2fXGHm   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185842  [1.02536, 1.1276305, 2.40779, -0.29763827, -1....                0   \n",
      "1185843  [-0.36215785, 0.9685337, 1.9971375, -0.8948023...                0   \n",
      "1185844  [-0.36215785, 0.9685337, 1.9971375, -0.8948023...                1   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185842                1                0  \n",
      "1185843                1                0  \n",
      "1185844                0                0  \n",
      "tensor([[[ 0.2627, -0.0315, -0.0079, -0.2996, -0.3976, -0.3182,  0.1922,\n",
      "           0.0935],\n",
      "         [ 0.3104,  0.1001,  0.2291, -0.3704, -0.5860, -0.4408,  0.2031,\n",
      "           0.1787],\n",
      "         [ 0.3403,  0.2695,  0.5064, -0.4407, -0.7830, -0.5562,  0.2036,\n",
      "           0.2771]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185845         125   0.997304      101  4a9i7rCLfPjbS1sNamZeQN   \n",
      "1185846         125   0.997304      101  4ICIjhyIi03aU3e4gIcSlP   \n",
      "1185847         125   0.997304      101  2RUhtNBh43RtSg0WBPPq3m   \n",
      "1185848         125   0.997304      101  2RUhtNBh43RtSg0WBPPq3m   \n",
      "1185849         125   0.997304      101  0cx32rX0uZvcJUP92Wkj2y   \n",
      "1185850         125   0.997304      101  5qBLfeAGlgGGsckKhsMWpF   \n",
      "1185851         125   0.997304      101  5qBLfeAGlgGGsckKhsMWpF   \n",
      "1185852         125   0.997304      101  5qBLfeAGlgGGsckKhsMWpF   \n",
      "1185853         125   0.997304      101  2o4ltEUubh8WST2Mh3nDTx   \n",
      "1185854         125   0.997305      101  1OqcfMMZrkxtQFRXFhk2j6   \n",
      "1185855         125   0.997305      101  1OqcfMMZrkxtQFRXFhk2j6   \n",
      "1185856         125   0.997305      101  2ePGxyry2I0xkN9hLppdaN   \n",
      "1185857         125   0.997305      101  6PmjWl0phNxc0R5OwkDdiZ   \n",
      "1185858         125   0.997305      101  6PmjWl0phNxc0R5OwkDdiZ   \n",
      "1185859         125   0.997305      101  0nCAVzknkzRXRgB6LhRv04   \n",
      "1185860         125   0.997305      101  73ucpKq91TuejrLHgzDNHK   \n",
      "1185861         125   0.997305      101  73ucpKq91TuejrLHgzDNHK   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185845  [0.40486258, 1.5139123, 0.836956, -1.2543375, ...                0   \n",
      "1185846  [1.5880734, 1.4312932, 1.9859962, -0.4252492, ...                0   \n",
      "1185847  [0.086986385, 1.6992769, 1.6990945, 0.07751874...                0   \n",
      "1185848  [0.086986385, 1.6992769, 1.6990945, 0.07751874...                0   \n",
      "1185849  [0.36745247, 1.7036073, 2.1720517, -0.2873002,...                0   \n",
      "1185850  [-0.10198305, 0.7839102, 1.265049, 0.8424942, ...                0   \n",
      "1185851  [-0.10198305, 0.7839102, 1.265049, 0.8424942, ...                1   \n",
      "1185852  [-0.10198305, 0.7839102, 1.265049, 0.8424942, ...                0   \n",
      "1185853  [0.13747652, 0.89300835, 0.3493376, -0.9320517...                0   \n",
      "1185854  [0.6569973, 1.7205963, 1.1242213, -1.9409881, ...                0   \n",
      "1185855  [0.6569973, 1.7205963, 1.1242213, -1.9409881, ...                1   \n",
      "1185856  [-0.21288128, 1.5652958, 1.1525774, -0.5418197...                0   \n",
      "1185857  [1.0057292, 2.4873857, 2.7256, -0.560028, -1.8...                0   \n",
      "1185858  [1.0057292, 2.4873857, 2.7256, -0.560028, -1.8...                1   \n",
      "1185859  [-0.25610188, 1.8614669, 1.4170632, -1.7329769...                0   \n",
      "1185860  [1.5542053, 1.7940991, 1.5206364, -0.98823774,...                0   \n",
      "1185861  [1.5542053, 1.7940991, 1.5206364, -0.98823774,...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185845                1                0  \n",
      "1185846                1                0  \n",
      "1185847                1                0  \n",
      "1185848                0                1  \n",
      "1185849                1                0  \n",
      "1185850                1                0  \n",
      "1185851                0                0  \n",
      "1185852                0                1  \n",
      "1185853                1                0  \n",
      "1185854                1                0  \n",
      "1185855                0                0  \n",
      "1185856                1                0  \n",
      "1185857                1                0  \n",
      "1185858                0                0  \n",
      "1185859                1                0  \n",
      "1185860                1                0  \n",
      "1185861                0                1  \n",
      "tensor([[[ 0.2621, -0.0361, -0.0138, -0.2991, -0.3958, -0.3183,  0.1934,\n",
      "           0.0900],\n",
      "         [ 0.3085,  0.0922,  0.2171, -0.3690, -0.5809, -0.4377,  0.2044,\n",
      "           0.1746],\n",
      "         [ 0.3373,  0.2562,  0.4848, -0.4360, -0.7707, -0.5478,  0.2047,\n",
      "           0.2703],\n",
      "         [ 0.3472,  0.4154,  0.7283, -0.4908, -0.9363, -0.6343,  0.2037,\n",
      "           0.3552],\n",
      "         [ 0.3461,  0.5372,  0.9055, -0.5256, -1.0559, -0.6886,  0.2038,\n",
      "           0.4179],\n",
      "         [ 0.3412,  0.6126,  1.0093, -0.5412, -1.1274, -0.7150,  0.2047,\n",
      "           0.4580],\n",
      "         [ 0.3369,  0.6551,  1.0663, -0.5459, -1.1673, -0.7268,  0.2046,\n",
      "           0.4817],\n",
      "         [ 0.3339,  0.6786,  1.0971, -0.5477, -1.1898, -0.7332,  0.2047,\n",
      "           0.4953],\n",
      "         [ 0.3318,  0.6906,  1.1133, -0.5479, -1.2018, -0.7368,  0.2048,\n",
      "           0.5022],\n",
      "         [ 0.3310,  0.6996,  1.1252, -0.5502, -1.2112, -0.7410,  0.2057,\n",
      "           0.5066],\n",
      "         [ 0.3306,  0.7057,  1.1332, -0.5520, -1.2180, -0.7444,  0.2065,\n",
      "           0.5088],\n",
      "         [ 0.3298,  0.7083,  1.1356, -0.5522, -1.2207, -0.7453,  0.2073,\n",
      "           0.5097],\n",
      "         [ 0.3297,  0.7119,  1.1402, -0.5535, -1.2242, -0.7471,  0.2076,\n",
      "           0.5111],\n",
      "         [ 0.3296,  0.7147,  1.1437, -0.5541, -1.2272, -0.7482,  0.2076,\n",
      "           0.5121],\n",
      "         [ 0.3297,  0.7161,  1.1453, -0.5555, -1.2290, -0.7498,  0.2086,\n",
      "           0.5121],\n",
      "         [ 0.3295,  0.7173,  1.1453, -0.5563, -1.2298, -0.7499,  0.2097,\n",
      "           0.5128],\n",
      "         [ 0.3298,  0.7183,  1.1462, -0.5573, -1.2308, -0.7512,  0.2102,\n",
      "           0.5126]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185862         126   0.966152      101  6dwhYg12fOFw8aUrnCOOqC   \n",
      "1185863         126   0.966152      101  6dwhYg12fOFw8aUrnCOOqC   \n",
      "1185864         126   0.966152      101  0UAJH0k4k3slcE83a9UGCe   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185862  [0.8274542, 1.767116, 1.2326163, -2.3152678, -...                0   \n",
      "1185863  [0.8274542, 1.767116, 1.2326163, -2.3152678, -...                0   \n",
      "1185864  [0.7362363, 1.8008469, 1.7532399, -1.2748411, ...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185862                1                0  \n",
      "1185863                0                1  \n",
      "1185864                1                0  \n",
      "tensor([[[ 0.2627, -0.0349, -0.0113, -0.3007, -0.3980, -0.3204,  0.1934,\n",
      "           0.0907],\n",
      "         [ 0.3097,  0.0890,  0.2157, -0.3718, -0.5837, -0.4423,  0.2047,\n",
      "           0.1729],\n",
      "         [ 0.3397,  0.2532,  0.4844, -0.4413, -0.7763, -0.5546,  0.2055,\n",
      "           0.2694]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185865         127   0.966962      101  4E3afPSY5fUEelQS9ppL0e   \n",
      "1185866         127   0.966962      101  4E3afPSY5fUEelQS9ppL0e   \n",
      "1185867         127   0.966963      101  4E3afPSY5fUEelQS9ppL0e   \n",
      "1185868         127   0.966963      101  426kUsOMW5p2VWEVNu5BxF   \n",
      "1185869         127   0.966963      101  426kUsOMW5p2VWEVNu5BxF   \n",
      "1185870         127   0.966963      101  70dJEanFPdYuWZumkrnKeX   \n",
      "1185871         127   0.966963      101  70dJEanFPdYuWZumkrnKeX   \n",
      "1185872         127   0.966963      101  70dJEanFPdYuWZumkrnKeX   \n",
      "1185873         127   0.966963      101  1Ovgu7X7u8zYoURU62ESmu   \n",
      "1185874         127   0.966963      101  1Ovgu7X7u8zYoURU62ESmu   \n",
      "1185875         127   0.966963      101  4z0PnuB07fxtVZZRWsCfxb   \n",
      "1185876         127   0.966963      101  4z0PnuB07fxtVZZRWsCfxb   \n",
      "1185877         127   0.966963      101  4z0PnuB07fxtVZZRWsCfxb   \n",
      "1185878         127   0.966963      101  4CLkDJ4xLqkV4Vt2vPOny1   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185865  [1.493064, 1.4639112, 1.8673233, -0.51920485, ...                0   \n",
      "1185866  [1.493064, 1.4639112, 1.8673233, -0.51920485, ...                1   \n",
      "1185867  [1.493064, 1.4639112, 1.8673233, -0.51920485, ...                0   \n",
      "1185868  [0.21035628, 1.5620365, 1.5128413, -0.7804438,...                0   \n",
      "1185869  [0.21035628, 1.5620365, 1.5128413, -0.7804438,...                0   \n",
      "1185870  [1.3191984, 1.3631092, 1.5267446, -1.1646445, ...                0   \n",
      "1185871  [1.3191984, 1.3631092, 1.5267446, -1.1646445, ...                1   \n",
      "1185872  [1.3191984, 1.3631092, 1.5267446, -1.1646445, ...                0   \n",
      "1185873  [0.7387147, 1.6595232, 1.6940241, -1.5168408, ...                0   \n",
      "1185874  [0.7387147, 1.6595232, 1.6940241, -1.5168408, ...                1   \n",
      "1185875  [0.71701133, 1.7022262, 1.362028, -1.4819434, ...                0   \n",
      "1185876  [0.71701133, 1.7022262, 1.362028, -1.4819434, ...                1   \n",
      "1185877  [0.71701133, 1.7022262, 1.362028, -1.4819434, ...                0   \n",
      "1185878  [-0.021623623, 1.2643408, 0.75735974, -0.80389...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185865                1                0  \n",
      "1185866                0                0  \n",
      "1185867                0                1  \n",
      "1185868                1                0  \n",
      "1185869                0                1  \n",
      "1185870                1                0  \n",
      "1185871                0                0  \n",
      "1185872                0                1  \n",
      "1185873                1                0  \n",
      "1185874                0                0  \n",
      "1185875                1                0  \n",
      "1185876                0                0  \n",
      "1185877                0                1  \n",
      "1185878                1                0  \n",
      "tensor([[[ 0.2627, -0.0313, -0.0080, -0.3000, -0.3980, -0.3189,  0.1928,\n",
      "           0.0928],\n",
      "         [ 0.3099,  0.1011,  0.2298, -0.3707, -0.5868, -0.4411,  0.2033,\n",
      "           0.1790],\n",
      "         [ 0.3390,  0.2710,  0.5077, -0.4417, -0.7845, -0.5571,  0.2039,\n",
      "           0.2781],\n",
      "         [ 0.3476,  0.4302,  0.7515, -0.4964, -0.9504, -0.6426,  0.2033,\n",
      "           0.3628],\n",
      "         [ 0.3457,  0.5480,  0.9217, -0.5296, -1.0666, -0.6943,  0.2041,\n",
      "           0.4234],\n",
      "         [ 0.3413,  0.6211,  1.0223, -0.5454, -1.1364, -0.7205,  0.2054,\n",
      "           0.4616],\n",
      "         [ 0.3376,  0.6623,  1.0776, -0.5512, -1.1758, -0.7332,  0.2058,\n",
      "           0.4838],\n",
      "         [ 0.3349,  0.6851,  1.1074, -0.5541, -1.1982, -0.7406,  0.2066,\n",
      "           0.4962],\n",
      "         [ 0.3328,  0.6972,  1.1231, -0.5545, -1.2103, -0.7439,  0.2070,\n",
      "           0.5030],\n",
      "         [ 0.3315,  0.7051,  1.1332, -0.5548, -1.2183, -0.7463,  0.2071,\n",
      "           0.5070],\n",
      "         [ 0.3308,  0.7100,  1.1383, -0.5559, -1.2232, -0.7481,  0.2082,\n",
      "           0.5094],\n",
      "         [ 0.3304,  0.7134,  1.1422, -0.5563, -1.2268, -0.7494,  0.2087,\n",
      "           0.5107],\n",
      "         [ 0.3302,  0.7158,  1.1447, -0.5572, -1.2293, -0.7509,  0.2094,\n",
      "           0.5114],\n",
      "         [ 0.3294,  0.7151,  1.1427, -0.5556, -1.2283, -0.7494,  0.2096,\n",
      "           0.5114]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185880         129   0.976943      101  2LthqyP0MLhGUBICwR1535   \n",
      "1185881         129   0.976944      101  3RRf5KNBCzK3uxWKRAC67q   \n",
      "1185882         129   0.976944      101  3RRf5KNBCzK3uxWKRAC67q   \n",
      "1185883         129   0.976944      101  38ofGhTF7TlGS4HkM6e2VS   \n",
      "1185884         129   0.976944      101  38ofGhTF7TlGS4HkM6e2VS   \n",
      "1185885         129   0.976944      101  1FJSXlDrgr9AS37w67CPHP   \n",
      "1185886         129   0.976944      101  1FJSXlDrgr9AS37w67CPHP   \n",
      "1185887         129   0.976944      101  1FJSXlDrgr9AS37w67CPHP   \n",
      "1185888         129   0.976944      101  76fUOrKOcUnAceODDPBidy   \n",
      "1185889         129   0.976944      101  76fUOrKOcUnAceODDPBidy   \n",
      "1185890         129   0.976944      101  3hENlPbIlUZXQ3MiosF87Q   \n",
      "1185891         129   0.976944      101  3hENlPbIlUZXQ3MiosF87Q   \n",
      "1185892         129   0.976944      101  6zGDIDjfDkPyNxrEERO3XG   \n",
      "1185893         129   0.976944      101  6zGDIDjfDkPyNxrEERO3XG   \n",
      "1185894         129   0.976944      101  09WxJCWFMWAxTHBLLelpDS   \n",
      "1185895         129   0.976944      101  09WxJCWFMWAxTHBLLelpDS   \n",
      "1185896         129   0.976944      101  7HjNOz8Y7H7uSySXuHNg1Y   \n",
      "1185897         129   0.976944      101  4wh0E9OwMCxcaIKTg0Mts9   \n",
      "1185898         129   0.976944      101  4wh0E9OwMCxcaIKTg0Mts9   \n",
      "1185899         129   0.976944      101  4hZAxSYVhaiFousCQM8LFc   \n",
      "1185900         129   0.976944      101  7x4ASXYEKfQBCewcZhK776   \n",
      "1185901         129   0.976944      101  7x4ASXYEKfQBCewcZhK776   \n",
      "1185902         129   0.976944      101  7hbk4BaF66O09R1gq0bKwj   \n",
      "1185903         129   0.976945      101  7hbk4BaF66O09R1gq0bKwj   \n",
      "1185904         129   0.976945      101  2MfOcbtgz2yTsiznFmVZUN   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185880  [0.18718143, 1.028642, 1.7514042, -0.17766258,...                0   \n",
      "1185881  [0.7949475, 0.8105425, 0.76770824, -1.2116957,...                0   \n",
      "1185882  [0.7949475, 0.8105425, 0.76770824, -1.2116957,...                0   \n",
      "1185883  [1.3041854, 1.4714705, 1.4149185, -1.2555606, ...                0   \n",
      "1185884  [1.3041854, 1.4714705, 1.4149185, -1.2555606, ...                1   \n",
      "1185885  [2.207489, 0.7315961, 1.3844784, -0.5330262, -...                0   \n",
      "1185886  [2.207489, 0.7315961, 1.3844784, -0.5330262, -...                1   \n",
      "1185887  [2.207489, 0.7315961, 1.3844784, -0.5330262, -...                0   \n",
      "1185888  [-0.33043975, 1.2309586, 0.58287, -0.8599334, ...                0   \n",
      "1185889  [-0.33043975, 1.2309586, 0.58287, -0.8599334, ...                1   \n",
      "1185890  [-0.4356219, 0.2676837, 0.6743224, -0.42329845...                0   \n",
      "1185891  [-0.4356219, 0.2676837, 0.6743224, -0.42329845...                0   \n",
      "1185892  [0.4532856, 1.1773511, 2.4905813, -0.77165955,...                0   \n",
      "1185893  [0.4532856, 1.1773511, 2.4905813, -0.77165955,...                0   \n",
      "1185894  [0.66548675, 0.8982821, 1.4805648, -0.10780094...                0   \n",
      "1185895  [0.66548675, 0.8982821, 1.4805648, -0.10780094...                0   \n",
      "1185896  [-1.0709945, 1.4976519, 2.302077, -0.03628056,...                0   \n",
      "1185897  [-1.1184379, 1.2886785, 2.2985656, 0.07598971,...                0   \n",
      "1185898  [-1.1184379, 1.2886785, 2.2985656, 0.07598971,...                0   \n",
      "1185899  [-0.25386825, 1.2261153, 1.0181704, -0.4670500...                0   \n",
      "1185900  [-0.50285435, 2.3464625, 2.2077613, -0.3522106...                0   \n",
      "1185901  [-0.50285435, 2.3464625, 2.2077613, -0.3522106...                0   \n",
      "1185902  [0.077202074, 1.6275972, 1.3505057, -0.3803859...                0   \n",
      "1185903  [0.077202074, 1.6275972, 1.3505057, -0.3803859...                1   \n",
      "1185904  [0.4761248, 1.5601033, 0.86078274, -1.4986911,...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185880                1                0  \n",
      "1185881                1                0  \n",
      "1185882                0                1  \n",
      "1185883                1                0  \n",
      "1185884                0                0  \n",
      "1185885                1                0  \n",
      "1185886                0                0  \n",
      "1185887                0                1  \n",
      "1185888                1                0  \n",
      "1185889                0                0  \n",
      "1185890                1                0  \n",
      "1185891                0                1  \n",
      "1185892                1                0  \n",
      "1185893                0                1  \n",
      "1185894                1                0  \n",
      "1185895                0                1  \n",
      "1185896                1                0  \n",
      "1185897                1                0  \n",
      "1185898                0                1  \n",
      "1185899                1                0  \n",
      "1185900                1                0  \n",
      "1185901                0                1  \n",
      "1185902                1                0  \n",
      "1185903                0                0  \n",
      "1185904                1                0  \n",
      "tensor([[[ 0.2633, -0.0328, -0.0106, -0.2996, -0.3965, -0.3188,  0.1930,\n",
      "           0.0908],\n",
      "         [ 0.3090,  0.0920,  0.2154, -0.3677, -0.5784, -0.4368,  0.2041,\n",
      "           0.1717],\n",
      "         [ 0.3370,  0.2524,  0.4787, -0.4352, -0.7676, -0.5474,  0.2047,\n",
      "           0.2663],\n",
      "         [ 0.3469,  0.4119,  0.7226, -0.4909, -0.9334, -0.6338,  0.2042,\n",
      "           0.3523],\n",
      "         [ 0.3461,  0.5343,  0.9003, -0.5257, -1.0534, -0.6880,  0.2045,\n",
      "           0.4156],\n",
      "         [ 0.3416,  0.6108,  1.0058, -0.5429, -1.1262, -0.7162,  0.2060,\n",
      "           0.4559],\n",
      "         [ 0.3379,  0.6541,  1.0647, -0.5496, -1.1676, -0.7305,  0.2065,\n",
      "           0.4792],\n",
      "         [ 0.3352,  0.6784,  1.0969, -0.5532, -1.1916, -0.7392,  0.2075,\n",
      "           0.4921],\n",
      "         [ 0.3326,  0.6902,  1.1129, -0.5521, -1.2037, -0.7416,  0.2072,\n",
      "           0.4992],\n",
      "         [ 0.3310,  0.6979,  1.1231, -0.5511, -1.2112, -0.7429,  0.2067,\n",
      "           0.5037],\n",
      "         [ 0.3301,  0.7037,  1.1300, -0.5520, -1.2168, -0.7447,  0.2074,\n",
      "           0.5070],\n",
      "         [ 0.3299,  0.7077,  1.1346, -0.5533, -1.2210, -0.7470,  0.2081,\n",
      "           0.5086],\n",
      "         [ 0.3300,  0.7117,  1.1396, -0.5547, -1.2249, -0.7489,  0.2086,\n",
      "           0.5101],\n",
      "         [ 0.3304,  0.7150,  1.1439, -0.5566, -1.2285, -0.7515,  0.2091,\n",
      "           0.5107],\n",
      "         [ 0.3297,  0.7152,  1.1433, -0.5560, -1.2285, -0.7507,  0.2095,\n",
      "           0.5110],\n",
      "         [ 0.3296,  0.7161,  1.1447, -0.5565, -1.2293, -0.7517,  0.2095,\n",
      "           0.5111],\n",
      "         [ 0.3296,  0.7176,  1.1466, -0.5565, -1.2308, -0.7518,  0.2094,\n",
      "           0.5119],\n",
      "         [ 0.3295,  0.7186,  1.1473, -0.5562, -1.2314, -0.7511,  0.2096,\n",
      "           0.5129],\n",
      "         [ 0.3297,  0.7196,  1.1487, -0.5566, -1.2324, -0.7518,  0.2095,\n",
      "           0.5130],\n",
      "         [ 0.3292,  0.7185,  1.1465, -0.5557, -1.2310, -0.7504,  0.2097,\n",
      "           0.5130],\n",
      "         [ 0.3292,  0.7186,  1.1468, -0.5553, -1.2307, -0.7501,  0.2094,\n",
      "           0.5131],\n",
      "         [ 0.3294,  0.7192,  1.1483, -0.5557, -1.2316, -0.7510,  0.2091,\n",
      "           0.5131],\n",
      "         [ 0.3291,  0.7188,  1.1468, -0.5553, -1.2309, -0.7498,  0.2095,\n",
      "           0.5134],\n",
      "         [ 0.3291,  0.7187,  1.1465, -0.5547, -1.2305, -0.7492,  0.2092,\n",
      "           0.5135],\n",
      "         [ 0.3289,  0.7178,  1.1453, -0.5544, -1.2295, -0.7489,  0.2093,\n",
      "           0.5132]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185905         130   0.968207      101  6rfNbeEGCh8M5AAj879g0r   \n",
      "1185906         130   0.968207      101  6rfNbeEGCh8M5AAj879g0r   \n",
      "1185907         130   0.968207      101  0k8LXt5uJ5O07BhSvnvjkY   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185905  [-0.05869321, 1.5161747, 1.5764964, -0.5217325...                0   \n",
      "1185906  [-0.05869321, 1.5161747, 1.5764964, -0.5217325...                1   \n",
      "1185907  [0.23393382, 2.1492293, 1.9724779, -1.8218443,...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185905                1                0  \n",
      "1185906                0                0  \n",
      "1185907                1                0  \n",
      "tensor([[[ 0.2629, -0.0361, -0.0136, -0.2995, -0.3962, -0.3190,  0.1931,\n",
      "           0.0897],\n",
      "         [ 0.3102,  0.0867,  0.2112, -0.3680, -0.5789, -0.4381,  0.2040,\n",
      "           0.1705],\n",
      "         [ 0.3416,  0.2555,  0.4878, -0.4404, -0.7771, -0.5544,  0.2051,\n",
      "           0.2704]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185909         132   0.978271      101  5lWRaa0fBxDE5yU91npPq7   \n",
      "1185910         132   0.978271      101  7I4ibsZgwuf46g0xHuTC8s   \n",
      "1185911         132   0.978271      101  7I4ibsZgwuf46g0xHuTC8s   \n",
      "1185912         132   0.978271      101  2VhJ4nrPorAbySEgO4V0BS   \n",
      "1185913         132   0.978271      101  2VhJ4nrPorAbySEgO4V0BS   \n",
      "1185914         132   0.978271      101  3op7HNwLli54MBjFGzIlZO   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185909  [-0.83454245, 1.0576999, 1.6971235, 0.03715236...                0   \n",
      "1185910  [-0.16417281, 1.5369322, 1.6645049, -1.0099375...                0   \n",
      "1185911  [-0.16417281, 1.5369322, 1.6645049, -1.0099375...                1   \n",
      "1185912  [0.023596015, 0.9002591, 1.4699925, -1.5787616...                0   \n",
      "1185913  [0.023596015, 0.9002591, 1.4699925, -1.5787616...                1   \n",
      "1185914  [0.06628253, 0.24026406, 0.113841064, -0.53293...                0   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185909                1                0  \n",
      "1185910                1                0  \n",
      "1185911                0                0  \n",
      "1185912                1                0  \n",
      "1185913                0                0  \n",
      "1185914                1                0  \n",
      "tensor([[[ 0.2630, -0.0333, -0.0105, -0.2994, -0.3967, -0.3187,  0.1931,\n",
      "           0.0913],\n",
      "         [ 0.3102,  0.0935,  0.2196, -0.3690, -0.5819, -0.4394,  0.2041,\n",
      "           0.1737],\n",
      "         [ 0.3404,  0.2587,  0.4910, -0.4382, -0.7760, -0.5527,  0.2045,\n",
      "           0.2707],\n",
      "         [ 0.3501,  0.4212,  0.7394, -0.4959, -0.9456, -0.6415,  0.2043,\n",
      "           0.3576],\n",
      "         [ 0.3480,  0.5429,  0.9151, -0.5304, -1.0647, -0.6950,  0.2048,\n",
      "           0.4197],\n",
      "         [ 0.3420,  0.6145,  1.0136, -0.5447, -1.1326, -0.7202,  0.2059,\n",
      "           0.4573]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185915         133   0.986323      101  3fo6DYGktjENCiagUeU9yH   \n",
      "1185916         133   0.986323      101  3fo6DYGktjENCiagUeU9yH   \n",
      "1185917         133   0.986323      101  1pKmfhwbZvsyYUP2eOGdw5   \n",
      "1185918         133   0.986323      101  6FYbr9QzRoZPh0Re8lDO9z   \n",
      "1185919         133   0.986323      101  4ai70kw4ToHz51iKd7VHA9   \n",
      "1185920         133   0.986323      101  4ai70kw4ToHz51iKd7VHA9   \n",
      "1185921         133   0.986323      101  7gCeodIXjhCLDWC5H1LOmT   \n",
      "1185922         133   0.986323      101  7gCeodIXjhCLDWC5H1LOmT   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185915  [0.4585946, 1.1321594, 1.1733357, -1.654238, -...                0   \n",
      "1185916  [0.4585946, 1.1321594, 1.1733357, -1.654238, -...                0   \n",
      "1185917  [-1.0565249, 0.7773401, 1.2794204, -0.71958387...                0   \n",
      "1185918  [-0.06008273, 1.5420535, 1.1088147, -1.6109637...                0   \n",
      "1185919  [0.6396917, 2.0052114, 2.6585677, -0.9941497, ...                0   \n",
      "1185920  [0.6396917, 2.0052114, 2.6585677, -0.9941497, ...                0   \n",
      "1185921  [0.7847434, 1.3656132, 2.3373773, -1.4057364, ...                0   \n",
      "1185922  [0.7847434, 1.3656132, 2.3373773, -1.4057364, ...                1   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185915                1                0  \n",
      "1185916                0                1  \n",
      "1185917                1                0  \n",
      "1185918                1                0  \n",
      "1185919                1                0  \n",
      "1185920                0                1  \n",
      "1185921                1                0  \n",
      "1185922                0                0  \n",
      "tensor([[[ 0.2628, -0.0332, -0.0093, -0.3004, -0.3982, -0.3200,  0.1932,\n",
      "           0.0919],\n",
      "         [ 0.3100,  0.0942,  0.2230, -0.3721, -0.5863, -0.4432,  0.2043,\n",
      "           0.1762],\n",
      "         [ 0.3391,  0.2599,  0.4939, -0.4412, -0.7796, -0.5556,  0.2050,\n",
      "           0.2729],\n",
      "         [ 0.3486,  0.4208,  0.7376, -0.4968, -0.9453, -0.6413,  0.2050,\n",
      "           0.3580],\n",
      "         [ 0.3474,  0.5435,  0.9144, -0.5311, -1.0640, -0.6946,  0.2055,\n",
      "           0.4202],\n",
      "         [ 0.3431,  0.6201,  1.0210, -0.5478, -1.1372, -0.7230,  0.2061,\n",
      "           0.4596],\n",
      "         [ 0.3386,  0.6623,  1.0779, -0.5537, -1.1773, -0.7359,  0.2067,\n",
      "           0.4825],\n",
      "         [ 0.3354,  0.6858,  1.1091, -0.5554, -1.1999, -0.7422,  0.2068,\n",
      "           0.4957]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n",
      "         session_id  timestamp  user_id                track_id  \\\n",
      "1185923         134   0.973976      101  7n2Dqgp4iXd8Zorfj9XSYo   \n",
      "1185924         134   0.973976      101  7n2Dqgp4iXd8Zorfj9XSYo   \n",
      "1185925         134   0.973976      101  7FEmLU7M5aZ5O7FlOdxB33   \n",
      "1185926         134   0.973976      101  2Gyc6e2cLxA5hoX1NOvYnU   \n",
      "1185927         134   0.973976      101  03LNdMgu3l3Ldc3QMl1bvZ   \n",
      "1185928         134   0.973977      101  03LNdMgu3l3Ldc3QMl1bvZ   \n",
      "1185929         134   0.973977      101  03LNdMgu3l3Ldc3QMl1bvZ   \n",
      "1185930         134   0.973977      101  35ItUJlMtjOQW3SSiTCrrw   \n",
      "1185931         134   0.973977      101  35ItUJlMtjOQW3SSiTCrrw   \n",
      "1185932         134   0.973977      101  5sXjuBJEVOaXyRwyIbMB4V   \n",
      "1185933         134   0.973977      101  28Kr5AR2XYD1PzXktkrsyx   \n",
      "1185934         134   0.973977      101  0E51ZB6sKXAnEC8JtYC8Sy   \n",
      "1185935         134   0.973977      101  60nZcImufyMA1MKQY3dcCH   \n",
      "1185936         134   0.973977      101  60nZcImufyMA1MKQY3dcCH   \n",
      "\n",
      "                                                  embeding  event_type_like  \\\n",
      "1185923  [-0.67487884, 0.6135279, 1.1703113, -0.2314434...                0   \n",
      "1185924  [-0.67487884, 0.6135279, 1.1703113, -0.2314434...                0   \n",
      "1185925  [-0.003094579, 0.905488, 1.0228184, -1.054708,...                0   \n",
      "1185926  [0.608018, 1.5597308, 0.8070646, -1.0623119, -...                0   \n",
      "1185927  [-0.29258117, 1.1507266, 2.3238542, -0.2951060...                0   \n",
      "1185928  [-0.29258117, 1.1507266, 2.3238542, -0.2951060...                1   \n",
      "1185929  [-0.29258117, 1.1507266, 2.3238542, -0.2951060...                0   \n",
      "1185930  [0.5502125, 0.58141756, 1.4665062, -1.0223634,...                0   \n",
      "1185931  [0.5502125, 0.58141756, 1.4665062, -1.0223634,...                1   \n",
      "1185932  [-0.785422, 1.596347, 1.061889, -0.64958185, -...                0   \n",
      "1185933  [-0.29832584, 1.147096, 2.3242733, -0.29538313...                0   \n",
      "1185934  [0.3563925, 1.1123406, 1.2985287, -0.8171788, ...                0   \n",
      "1185935  [1.3382139, 1.4239051, 1.9032459, -1.3849502, ...                0   \n",
      "1185936  [1.3382139, 1.4239051, 1.9032459, -1.3849502, ...                1   \n",
      "\n",
      "         event_type_play  event_type_skip  \n",
      "1185923                1                0  \n",
      "1185924                0                1  \n",
      "1185925                1                0  \n",
      "1185926                1                0  \n",
      "1185927                1                0  \n",
      "1185928                0                0  \n",
      "1185929                0                1  \n",
      "1185930                1                0  \n",
      "1185931                0                0  \n",
      "1185932                1                0  \n",
      "1185933                1                0  \n",
      "1185934                1                0  \n",
      "1185935                1                0  \n",
      "1185936                0                0  \n",
      "tensor([[[ 0.2629, -0.0361, -0.0159, -0.2978, -0.3928, -0.3168,  0.1932,\n",
      "           0.0876],\n",
      "         [ 0.3082,  0.0812,  0.1981, -0.3633, -0.5680, -0.4311,  0.2040,\n",
      "           0.1631],\n",
      "         [ 0.3380,  0.2386,  0.4558, -0.4300, -0.7537, -0.5393,  0.2047,\n",
      "           0.2561],\n",
      "         [ 0.3482,  0.3946,  0.6959, -0.4846, -0.9174, -0.6250,  0.2037,\n",
      "           0.3413],\n",
      "         [ 0.3478,  0.5226,  0.8829, -0.5224, -1.0428, -0.6830,  0.2040,\n",
      "           0.4087],\n",
      "         [ 0.3434,  0.6059,  1.0002, -0.5412, -1.1225, -0.7144,  0.2045,\n",
      "           0.4527],\n",
      "         [ 0.3390,  0.6541,  1.0661, -0.5497, -1.1687, -0.7309,  0.2052,\n",
      "           0.4789],\n",
      "         [ 0.3355,  0.6795,  1.0996, -0.5525, -1.1930, -0.7382,  0.2062,\n",
      "           0.4934],\n",
      "         [ 0.3333,  0.6941,  1.1188, -0.5535, -1.2074, -0.7426,  0.2065,\n",
      "           0.5014],\n",
      "         [ 0.3316,  0.7015,  1.1275, -0.5533, -1.2147, -0.7443,  0.2072,\n",
      "           0.5056],\n",
      "         [ 0.3309,  0.7081,  1.1356, -0.5543, -1.2209, -0.7464,  0.2077,\n",
      "           0.5090],\n",
      "         [ 0.3306,  0.7119,  1.1392, -0.5553, -1.2246, -0.7476,  0.2088,\n",
      "           0.5109],\n",
      "         [ 0.3304,  0.7142,  1.1418, -0.5561, -1.2267, -0.7492,  0.2093,\n",
      "           0.5114],\n",
      "         [ 0.3303,  0.7162,  1.1447, -0.5567, -1.2290, -0.7508,  0.2093,\n",
      "           0.5116]]], grad_fn=<ViewBackward0>)\n",
      "____________________________\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data in merged_sesions_data:\n",
    "    sessions = []\n",
    "    i += 1\n",
    "    for session in (\n",
    "        data.drop(\"track_id\", axis=1)\n",
    "        .drop(\"session_id\", axis=1)\n",
    "        .drop(\"user_id\", axis=1)\n",
    "        .values\n",
    "    ):\n",
    "        unpacked_data = np.array([])\n",
    "        for element in session:\n",
    "            unpacked_data = np.append(unpacked_data, element)\n",
    "        sessions.append(torch.tensor(unpacked_data))\n",
    "    sessions = torch.stack(sessions)\n",
    "    print(data)\n",
    "    print(model.cpu()(torch.stack([sessions]).float(), torch.tensor([len(sessions)])))\n",
    "    print(\"____________________________\")\n",
    "    if i > 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model.cpu())\n",
    "model_scripted.save(\"recomendation_models/scripted_user_preference_model_v1_8_dim.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
